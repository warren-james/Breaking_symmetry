---
title: "Supplementary Material for Asymmetry paper"
output: 
  bookdown::pdf_document2
---

---
title: "Supplementary Material For Asymmetry paper"
output: html_document
---

```{r setup, include=T, message=F, warning=F, echo= F}
# library 
library(tidybayes)
library(tidyverse)
library(brms)
```


# Power Analysis

Our power analysis made use of simulations and resampling approaches based on data that we previously collected. Resampling was carried out in order to establish if adding more pariticipants to our sample sizes would have lead to a reduction in uncertainty around our estimates.

## Experiment 1: Two Hoop Sizes

```{r loaddata, include = T, echo = F, fig.height = 3, fig.cap="Warren write some text."}
load("../power/Hoop_size/scratch/sampled_data")
load("../power/Hoop_size/scratch/df_part2")
```

We started by fitting a a beta distribution to the _Throwing Experiment_ data from Clarke and Hunt (2016) using the `fitdistrplus` package, as illustrated in Figure \@ref(fig:drawdistributions) (left panel). The fit with the empirical data is reasonable, although we under-estimate the frequency of standing positions $\sim0$.

We then investigated how well we could detect various effects (i.e., increases in the mean from $\mu=0$ to $\mu=0.01$), and how this varied based on the sample size.  

We altered the mean value but kept the variance the same to simulate participants shifting in one direction or the other. As can be seen in the figure below, we tested $X \in \{5\%, 10\%, 15\%, 20\%\}$ which were indicative of participants standing $X\%$ closer to the smaller hoop. These distributions were sampled from 5000 times by simulating $N = 3\ldots 24$ participants and 72 trials. 

```{r drawdistributions, include = T, echo = F, fig.height = 3, fig.cap="The left hand plot shows a histrogram for the empirical data from Clarke and Hunt (2016) with a line to show a beta distribution that had been fit to these data. The right hand plot shows how this distribution would change had the participants' mean position had been biased towards one of the side hoops to varying degrees."}
load("../power/Hoop_size/scratch/sampled_data")
load("../power/Hoop_size/scratch/df_part2")

# functions for getting parameters from a beta dist
mu_beta <- function(a, b){
  a/(a + b)
}
phi_beta <- function(a, b){
  1/((a*b)/(((a+b)^2)*(a+b+1)))
}
var_beta <- function(a, b){
  (a*b)/(((a+b)^2)*(a+b+1))
}

# get shape parameters 
get_shape_beta <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}

# sort out beta shape
shape_1 <- fitdistrplus::fitdist(df_part2$beta_pos, "beta")
mu1 <- mu_beta(shape_1$estimate[1], shape_1$estimate[2])
var1 <- var_beta(shape_1$estimate[1], shape_1$estimate[2])
shape_1 <- get_shape_beta(mu1, var1)
mu2 <- seq(0.05, .2, 0.05)
x <- seq(0,1,0.0005)

# draw these 
df_distributions <- tibble(x_vals = rep(x, length(c(0,mu2))),
                           base = mu1,
                           diff = rep(c(0,mu2), each = length(x)),
                           var = var1,
                           alpha = get_shape_beta(base + diff, var)$alpha,
                           beta = get_shape_beta(base + diff, var)$beta,
                           est_mu = mu_beta(alpha, beta),
                           est_var = var_beta(alpha, beta),
                           p = dbeta(x_vals, alpha, beta))

plt_both <- df_distributions %>% 
  mutate(diff = as.factor(diff)) %>%
  ggplot(aes(x_vals, p)) + 
  geom_histogram(data = df_part2, 
                 aes(x = (norm_pos + 1)/2,
                     y = ..density..),
                 binwidth = .1,
                 colour = "blue",
                 fill = "blue",
                 alpha = .2) + 
  geom_line(aes(colour = diff)) + 
  theme_bw() + 
  see::scale_color_flat() +
  guides(colour = guide_legend("Difference")) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "bottom")

plt_dists <- df_distributions %>% 
  mutate(diff = as.factor(diff)) %>% 
  ggplot(aes(x_vals, p)) + 
  geom_line(aes(colour = diff)) + 
  theme_bw() + 
  see::scale_color_flat() +
  guides(colour = guide_legend("Difference")) + 
  theme(
    axis.title = element_blank(),
    legend.title = element_blank(),
    legend.position = "right"
  )

plt_hist <- df_distributions %>% 
  filter(diff == 0) %>% 
  mutate(diff = as.factor(diff)) %>% 
  ggplot(aes(x_vals, p)) + 
  geom_line(aes(colour = diff)) + 
  see::scale_color_flat() + 
  theme_bw() + 
  geom_histogram(data = df_part2, 
                 aes(x = (norm_pos + 1)/2, y = ..density..),
                 binwidth = .1,
                 colour = "blue", 
                 fill = "blue",
                 alpha = .2) + 
  theme(
    legend.position = "none",
    axis.title = element_blank()
    )

# plt_hist <- df_part2 %>% 
#   ggplot(aes((norm_pos +1)/2, y = ..density..)) + 
#   geom_histogram(binwidth = .1, 
#                  colour = "blue",
#                  fill = "blue",
#                  alpha = .2) + 
#   theme_bw() + 
#   theme(
#     axis.title = element_blank()
#   )

gridExtra::grid.arrange(plt_hist, plt_dists, ncol = 2)
```

Figure \@ref(fig:HDIHoopSize) shows the uncertainty surrounding the mean estimate for the smallest difference tested (5\%). After 15 participants, the uncertainty surrounding the estimate appears to plateau which demonstrates that the sample size of 21 was sufficient to detect the effect. 

```{r HDIHoopSize, include = T, echo = F, fig.height = 3, fig.cap="This figure shows how the 95% HDI around the mean difference for the smallest difference simulated (5%) changed with a larger sample size"}

df_sample %>% 
  filter(difference == 0.05) %>% 
  group_by(n_subs) %>% 
  mutate(diff = comparison - baseline) %>% 
  summarise(mu = mean(diff), 
            lower = hdi(diff)[1],
            upper = hdi(diff)[2]) %>% 
  ggplot(aes(n_subs, mu)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower,
                  ymax = upper),
              alpha = .3) + 
  scale_x_continuous("Sample Size") + 
  theme_bw() + 
  theme(axis.title.y = element_blank())

```



## Experiment 2 and 3: Two Throws and Reward
As the hypothesis for both of these experiments was that out intervention would push participants towards being more optimal, we can use the same datasets to look at how uncertainty around the difference would change with varying sample sizes. For these experiments, comparison data was drawn from two unpublished studies; one in which the standard behaviour was observed, and one in which participants were closer to optimal in their performance.

The first dataset is comprised of 40 participants who took part in a version of the Clarke and Hunt (2016) _Throwing Task_. The second dataset is comprised of 60 participants who took part in a computerised version of this task. To compare these datasets, placement positions and standing positions were put on the same scale (0 being the centre and 1 being stood/placed next to the target). Only data for the easiest (smallest separataion of targets) and hard (furthest separation of targets) conditions were considered as these points offered more comparable base performance levels. 

```{r Exp2and3Plots, include = T, echo = F, fig.cap="The top plot shows boxplots for the empirical data being sampled from. The bottom plots show the 95% HDI for the difference in the close (90%) and far (10%) separations"}
# so we're interested in the difference between the closest and furthest... 
# so we should just plot that? 
load("../power/Money_and_two/scratch/df_sample")
load("../power/Money_and_two/scratch/df_all")
plt_data <- df_all %>%
  filter(standard_lab %in% c("10%","90%")) %>%
  group_by(participant, condition, standard_lab) %>% 
  summarise(norm_pos = mean(norm_pos)) %>%
  ggplot(aes(standard_lab, norm_pos,
             colour = condition,
             fill = condition)) + 
  geom_boxplot(alpha = .3) + 
  geom_point(alpha = .3, position = position_jitterdodge(.1)) + 
  see::scale_color_flat() + 
  see::scale_fill_flat() + 
  theme_bw() +
  scale_y_continuous("Normalised Placement") +
  theme(axis.title.x = element_blank()) + 
  guides(colour = guide_legend(title = "Condition"),
         fill = guide_legend(title = "Condition"))

plt_data_diff <- plt_data[["data"]] %>%
  ungroup() %>% 
  spread(standard_lab, norm_pos) %>% 
  mutate(diff = `90%` - `10%`) %>% 
  ggplot(aes(condition, diff,
             colour = condition, 
             fill = condition)) + 
  geom_boxplot(alpha = .3) + 
  geom_point(alpha = .3, position = position_jitterdodge(.1))
  
# plot samples in terms of difference? 
plt_hdi <- df_sample %>% 
  filter(n_trials != 12,
         n_subs != 2) %>%
  mutate(diff = baseline - comparison) %>% 
  group_by(n_subs, dist_type) %>% 
  summarise(mu = mean(diff),
            upper = hdi(diff)[2],
            lower = hdi(diff)[1]) %>% 
  ggplot(aes(n_subs, mu)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper),
              alpha = .3) + 
  facet_wrap(~dist_type) + 
  theme_bw() + 
  scale_x_continuous("Sample Size") + 
  scale_y_continuous("Difference: Athletes - Avatar")

# show both 
gridExtra::grid.arrange(plt_data, plt_hdi, ncol = 1)
  
```

# Session Info


```{r}
sessionInfo()
```